{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Milestone I Natural Language Processing\n",
    "## Task 2&3\n",
    "#### Student Name: Tharkana Vishmika Indrahenaka Henaka Ralalage\n",
    "#### Student ID: s4065784\n",
    "\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include all the libraries you used in your assignment, e.g.,:\n",
    "* pandas\n",
    "* re\n",
    "* numpy\n",
    "\n",
    "## Introduction\n",
    "In this assignment, you will focus on text processing and feature extraction of clothing reviews to build and evaluate classification algorithms. Features representations via BoW and unweighted/TF-IDF weighted word embeddings in **Task 2** also explored the contributions of them on influenced the model. The goal of **Task 3** was to determine whether the addition of said features and the concatenation review text with title would improve classification accuracy an overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to import libraries as you need in this assessment, e.g.,\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm \n",
    "from scipy.sparse import dok_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Generating Feature Representations for Clothing Items Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data and Vocabulary\n",
    "Load processed.csv and vocab.txt to ensure you have access to the processed reviews and vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 7549\n"
     ]
    }
   ],
   "source": [
    "# Load processed data (assuming the column 'Review Text' contains the processed reviews)\n",
    "df = pd.read_csv('processed.csv')\n",
    "\n",
    "# Load the vocabulary with word indices\n",
    "vocab = {}\n",
    "with open('vocab.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        word, idx = line.strip().split(':')\n",
    "        vocab[word] = int(idx)\n",
    "\n",
    "# Confirm that the vocabulary is loaded correctly\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handle NaN Values\n",
    "Identified NaN values and replace them with an empty string to maintain consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Replace NaN values in 'Review Text' with an empty string\n",
    "df['Processed_Review'].fillna('No review', inplace=True)\n",
    "\n",
    "# Confirm that there are no more NaN values\n",
    "print(df['Processed_Review'].isnull().sum())  # Should print 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate Count Vector Representations (Bag-of-Words Model)\n",
    "Use CountVectorizer to generate count vectors based on vocabulary from Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CountVectorizer using the provided vocabulary\n",
    "vectorizer = CountVectorizer(vocabulary=vocab.keys())\n",
    "\n",
    "# Transform the review text into count vectors (only 'Review Text' column)\n",
    "count_vectors = vectorizer.transform(df['Processed_Review'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate Embedding-Based Feature Representations\n",
    "Using GoogleNews-vectors-negative300.bin as the pre-trained word embedding model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Note:** Before executing the .ipynb files, please ensure that the GoogleNews-vectors-negative300.bin file is downloaded, extracted from its zip archive, and placed in the same directory as the notebook. This is required to properly load the pretrained word vectors for the embedding-based feature representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Unweighted Vectors: 100%|██████████| 19662/19662 [00:03<00:00, 5568.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained word embedding model\n",
    "embedding_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Define a function to generate the unweighted vector representation\n",
    "def get_unweighted_vector(review):\n",
    "    words = review.split()\n",
    "    word_vectors = [embedding_model[word] for word in words if word in embedding_model]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embedding_model.vector_size)\n",
    "\n",
    "# Generate unweighted vectors for each review\n",
    "unweighted_vectors = np.array([get_unweighted_vector(review) for review in tqdm(df['Processed_Review'], desc=\"Generating Unweighted Vectors\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate Weighted Embedding Representations (TF-IDF Weighted)\n",
    "Use TfidfVectorizer to generate TF-IDF weights and incorporate them into the word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Weighted Vectors: 100%|██████████| 19662/19662 [00:07<00:00, 2551.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a TF-IDF vectorizer using the same vocabulary\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=vocab.keys())\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['Processed_Review'])\n",
    "\n",
    "# Map vocabulary indices to their corresponding words\n",
    "index_to_word = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Define a function to generate the weighted vector representation\n",
    "def get_weighted_vector(review_index):\n",
    "    tfidf_scores = tfidf_matrix[review_index]\n",
    "    weighted_vectors = []\n",
    "    for idx, score in zip(tfidf_scores.indices, tfidf_scores.data):\n",
    "        word = index_to_word[idx]\n",
    "        if word in embedding_model:\n",
    "            weighted_vectors.append(embedding_model[word] * score)\n",
    "    if weighted_vectors:\n",
    "        return np.sum(weighted_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embedding_model.vector_size)\n",
    "\n",
    "# Generate weighted vectors for each review\n",
    "weighted_vectors = np.array([get_weighted_vector(i) for i in tqdm(range(len(df)), desc=\"Generating Weighted Vectors\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving outputs\n",
    "Save the count vector representation as per spectification.\n",
    "- count_vectors.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Count Vectors: 100%|██████████| 19662/19662 [00:09<00:00, 2045.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# code to save output data...\n",
    "# Save count_vectors to count_vectors.txt in the required format\n",
    "with open('count_vectors.txt', 'w') as f:\n",
    "    for i in tqdm(range(count_vectors.shape[0]), desc=\"Generating Count Vectors\"):\n",
    "        indices = count_vectors[i].indices\n",
    "        counts = count_vectors[i].data\n",
    "        # Create the sparse format as required: #webindex,word_idx:count\n",
    "        row_representation = f\"#{i},\" + \",\".join([f\"{indices[j]}:{counts[j]}\" for j in range(len(indices))])\n",
    "        f.write(row_representation + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save unweighted vectors and weighted vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unweighted vectors to unweighted_vectors.txt\n",
    "with open('unweighted_vectors.txt', 'w') as f:\n",
    "    for i, vector in enumerate(unweighted_vectors):\n",
    "        vector_str = ','.join(map(str, vector))\n",
    "        f.write(f\"#{i},{vector_str}\\n\")\n",
    "\n",
    "# Save weighted vectors to weighted_vectors.txt\n",
    "with open('weighted_vectors.txt', 'w') as f:\n",
    "    for i, vector in enumerate(weighted_vectors):\n",
    "        vector_str = ','.join(map(str, vector))\n",
    "        f.write(f\"#{i},{vector_str}\\n\")\n",
    "\n",
    "# Save unweighted vectors to unweighted_vectors.npy\n",
    "np.save('unweighted_vectors.npy', unweighted_vectors)\n",
    "\n",
    "# Save weighted vectors to weighted_vectors.npy\n",
    "np.save('weighted_vectors.npy', weighted_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Clothing Review Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load Data and Feature Representations\n",
    "Need to load the processed data and the feature representations (count vectors, unweighted vectors, and weighted vectors) generated in Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Load processed dataset\n",
    "df = pd.read_csv('processed.csv')\n",
    "\n",
    "# Replace NaN values in 'Review Text' with an empty string\n",
    "df['Processed_Review'].fillna('No review', inplace=True)\n",
    "\n",
    "# Confirm that there are no more NaN values\n",
    "print(df['Processed_Review'].isnull().sum())  # Should print 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df: 19662\n",
      "Length of full_df: 19662\n"
     ]
    }
   ],
   "source": [
    "# Load the full dataset which contains the 'Title' column\n",
    "full_df = pd.read_csv('assignment3.csv')\n",
    "\n",
    "print(\"Length of df:\", len(df))\n",
    "print(\"Length of full_df:\", len(full_df))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined_df: (19662, 2)\n"
     ]
    }
   ],
   "source": [
    "# Reset the index of `df` to ensure proper alignment\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Filter `full_df` based on the index of `df` to ensure they match\n",
    "full_df_filtered = full_df.loc[df.index].reset_index(drop=True)\n",
    "\n",
    "# Create the combined DataFrame using `df` and the filtered `full_df`\n",
    "combined_df = pd.DataFrame({\n",
    "    'Processed_Review': df['Processed_Review'],\n",
    "    'Recommended IND': full_df_filtered['Recommended IND']\n",
    "})\n",
    "\n",
    "# Check the shape of combined_df\n",
    "print(\"Shape of combined_df:\", combined_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load count vector representation\n",
    "count_vectors = []\n",
    "with open('count_vectors.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(',')\n",
    "        vector = {int(word.split(':')[0]): int(word.split(':')[1]) for word in parts[1:] if word}  # Ensure word is not empty\n",
    "        count_vectors.append(vector)\n",
    "\n",
    "# Convert count_vectors into a sparse matrix (assuming same dimensions as vocab size)\n",
    "vocab_size = len(open('vocab.txt').readlines())  # Length of vocabulary\n",
    "X_count = dok_matrix((len(count_vectors), vocab_size))\n",
    "\n",
    "for i, vector in enumerate(count_vectors):\n",
    "    for word_index, freq in vector.items():\n",
    "        X_count[i, word_index] = freq\n",
    "\n",
    "# Load unweighted and weighted vectors\n",
    "unweighted_vectors = np.load('unweighted_vectors.npy')\n",
    "weighted_vectors = np.load('weighted_vectors.npy')\n",
    "\n",
    "# Load labels for classification task from 'Recommended IND'\n",
    "y = combined_df['Recommended IND'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_count: (19662, 7549)\n",
      "Shape of unweighted_vectors: (19662, 300)\n",
      "Shape of weighted_vectors: (19662, 300)\n",
      "Length of y: 19662\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_count:\", X_count.shape)\n",
    "print(\"Shape of unweighted_vectors:\", unweighted_vectors.shape)\n",
    "print(\"Shape of weighted_vectors:\", weighted_vectors.shape)\n",
    "print(\"Length of y:\", len(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choose Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1 - Language Model Comparisons\n",
    "For Q1, train and evaluate each model on all three feature representations: count vectors, unweighted vectors, and weighted vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n",
      "On Count Vectors:\n",
      "On Unweighted Vectors:\n",
      "On Weighted Vectors:\n",
      "                                        accuracy  precision    recall  \\\n",
      "Logistic Regression Count Vectors       0.875038   0.903373  0.948779   \n",
      "                    Unweighted Vectors  0.858559   0.873396  0.967365   \n",
      "                    Weighted Vectors    0.861611   0.884891  0.955119   \n",
      "\n",
      "                                              f1  \n",
      "Logistic Regression Count Vectors       0.925508  \n",
      "                    Unweighted Vectors  0.917978  \n",
      "                    Weighted Vectors    0.918656  \n"
     ]
    }
   ],
   "source": [
    "# Function to perform 5-fold cross-validation and return average metrics\n",
    "def evaluate_model(model, X, y):\n",
    "    accuracy = cross_val_score(model, X, y, cv=5, scoring='accuracy').mean()\n",
    "    precision = cross_val_score(model, X, y, cv=5, scoring='precision').mean()\n",
    "    recall = cross_val_score(model, X, y, cv=5, scoring='recall').mean()\n",
    "    f1 = cross_val_score(model, X, y, cv=5, scoring='f1').mean()\n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "# Evaluate models on count vectors, unweighted vectors, and weighted vectors\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    # Count Vectors\n",
    "    print(\"On Count Vectors:\")\n",
    "    results[(model_name, 'Count Vectors')] = evaluate_model(model, X_count, y)\n",
    "    \n",
    "    # Unweighted Embedding Vectors\n",
    "    print(\"On Unweighted Vectors:\")\n",
    "    results[(model_name, 'Unweighted Vectors')] = evaluate_model(model, unweighted_vectors, y)\n",
    "    \n",
    "    # Weighted Embedding Vectors\n",
    "    print(\"On Weighted Vectors:\")\n",
    "    results[(model_name, 'Weighted Vectors')] = evaluate_model(model, weighted_vectors, y)\n",
    "\n",
    "# Convert results to a DataFrame for better visualization\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that performed the best in evaluating the **Logistic Regression model** was the **Count Vectors (Bag of Words)**, which got an accuracy of 87.53%, precision of 90.35%, recall of 94.90% and f1-score of 92.57%. It shows the Count Vector representation is capturing the most amount of predictive information in classification of clothing reviews. The **Unweighted** and **TF-IDF Weighted Embedding Vectors** had slightly lower accuracy (85.87% and 86.19%, respectively), but still with high recall, which poses a wide net for positive cases. To put it all together, the performance of extracted features in terms of performance and generalization capabilities are precisely evaluated and we can conclude that the Count Vector representation by itself has been able to provide excellent overall balance compared to other feature representation models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2 - Effect of Additional Features (Title & Review Text)\n",
    "Generate feature vectors for 'Title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clothing ID                0\n",
      "Age                        0\n",
      "Title                      0\n",
      "Review Text                0\n",
      "Rating                     0\n",
      "Recommended IND            0\n",
      "Positive Feedback Count    0\n",
      "Division Name              0\n",
      "Department Name            0\n",
      "Class Name                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the full dataset which contains the 'Title' column\n",
    "full_df = pd.read_csv('assignment3.csv')\n",
    "\n",
    "# Check for null values in the DataFrame\n",
    "null_values = full_df.isnull().sum()\n",
    "\n",
    "# Display the columns with their corresponding count of null values\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Count Vectors for Title**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'Title' column and fill NaNs with empty strings\n",
    "titles = full_df['Title'].fillna('')\n",
    "\n",
    "# Use the same vocabulary from Task 1 to generate count vectors for `Title`\n",
    "title_vectorizer = CountVectorizer(vocabulary=vocab.keys())\n",
    "\n",
    "# Transform the title text into count vectors\n",
    "title_count_vectors = title_vectorizer.transform(titles)\n",
    "\n",
    "# Save the count vectors to a .txt file\n",
    "with open('title_count_vectors.txt', 'w') as f:\n",
    "    for i in range(title_count_vectors.shape[0]):\n",
    "        indices = title_count_vectors[i].indices\n",
    "        counts = title_count_vectors[i].data\n",
    "        row_representation = f\"#{i},\" + \" \".join([f\"{indices[j]}:{counts[j]}\" for j in range(len(indices))])\n",
    "        f.write(row_representation + \"\\n\")\n",
    "\n",
    "# Save count vectors to .npy file\n",
    "np.save('title_count_vectors.npy', title_count_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Unweighted Embedding Vectors for Title**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to generate unweighted vector for each title\n",
    "def get_unweighted_title_vector(title):\n",
    "    words = title.split()\n",
    "    word_vectors = [embedding_model[word] for word in words if word in embedding_model]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embedding_model.vector_size)\n",
    "\n",
    "# Generate unweighted vectors for `Title`\n",
    "title_unweighted_vectors = np.array([get_unweighted_title_vector(title) for title in titles])\n",
    "\n",
    "# Save unweighted vectors to a .txt file\n",
    "with open('title_unweighted_vectors.txt', 'w') as f:\n",
    "    for i, vector in enumerate(title_unweighted_vectors):\n",
    "        vector_str = ','.join(map(str, vector))\n",
    "        f.write(f\"#{i},{vector_str}\\n\")\n",
    "\n",
    "# Save unweighted vectors to .npy file\n",
    "np.save('title_unweighted_vectors.npy', title_unweighted_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Weighted Embedding Vectors for Title Using TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate TF-IDF weights for `Title`\n",
    "title_tfidf_vectorizer = TfidfVectorizer(vocabulary=vocab.keys())\n",
    "title_tfidf_matrix = title_tfidf_vectorizer.fit_transform(titles)\n",
    "\n",
    "# Define function to generate weighted vector for each title\n",
    "def get_weighted_title_vector(title_index):\n",
    "    tfidf_scores = title_tfidf_matrix[title_index]\n",
    "    weighted_vectors = []\n",
    "    for idx, score in zip(tfidf_scores.indices, tfidf_scores.data):\n",
    "        word = index_to_word[idx]\n",
    "        if word in embedding_model:\n",
    "            weighted_vectors.append(embedding_model[word] * score)\n",
    "    if weighted_vectors:\n",
    "        return np.sum(weighted_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embedding_model.vector_size)\n",
    "\n",
    "# Generate weighted vectors for `Title`\n",
    "title_weighted_vectors = np.array([get_weighted_title_vector(i) for i in range(len(titles))])\n",
    "\n",
    "# Save weighted vectors to a .txt file\n",
    "with open('title_weighted_vectors.txt', 'w') as f:\n",
    "    for i, vector in enumerate(title_weighted_vectors):\n",
    "        vector_str = ','.join(map(str, vector))\n",
    "        f.write(f\"#{i},{vector_str}\\n\")\n",
    "\n",
    "# Save weighted vectors to .npy file\n",
    "np.save('title_weighted_vectors.npy', title_weighted_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine and Evaluate Feature Representations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Title Count Vectors: 0.8747839252546274\n",
      "Accuracy using Title Unweighted Vectors: 0.8690872728580116\n",
      "Accuracy using Title Weighted Vectors: 0.869138641937085\n",
      "Accuracy using Combined Unweighted Vectors: 0.8894819741349187\n",
      "Accuracy using Combined Weighted Vectors: 0.8886173776990429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load existing `Processed_Review` vectors (already generated)\n",
    "unweighted_vectors = np.load('unweighted_vectors.npy')\n",
    "weighted_vectors = np.load('weighted_vectors.npy')\n",
    "\n",
    "# Combine `Title` and `Processed_Review` vectors\n",
    "combined_unweighted_vectors = np.hstack((title_unweighted_vectors, unweighted_vectors))\n",
    "combined_weighted_vectors = np.hstack((title_weighted_vectors, weighted_vectors))\n",
    "\n",
    "# Save combined weighted vectors to a .npy file\n",
    "np.save('combined_weighted_vectors.npy', combined_weighted_vectors)\n",
    "\n",
    "# Define model for evaluation\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(X, y):\n",
    "    accuracy = cross_val_score(model, X, y, cv=5, scoring='accuracy').mean()\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate using Title only\n",
    "print(\"Accuracy using Title Count Vectors:\", evaluate_model(title_count_vectors, full_df['Recommended IND']))\n",
    "print(\"Accuracy using Title Unweighted Vectors:\", evaluate_model(title_unweighted_vectors, full_df['Recommended IND']))\n",
    "print(\"Accuracy using Title Weighted Vectors:\", evaluate_model(title_weighted_vectors, full_df['Recommended IND']))\n",
    "\n",
    "# Evaluate combined vectors\n",
    "print(\"Accuracy using Combined Unweighted Vectors:\", evaluate_model(combined_unweighted_vectors, full_df['Recommended IND']))\n",
    "print(\"Accuracy using Combined Weighted Vectors:\", evaluate_model(combined_weighted_vectors, full_df['Recommended IND']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the results, adding more data (the title) definitely helps the model learn better. Using just the title vectors, the model managed **87.45%** accuracy for Count Vectors, **86.92%** accuracy for Unweighted Embeddings and an accuracy of **86.97%** with TF-IDF Weighted Embeddings. The overall shifted from 79.5% to around **88.96%** for Unweighted Embeddings and TF-IDF Weighted Embeddings. And this means that adding both the title and description in a review helps improve how well our model does, implying that more data generally leads to better predictions. When features are combined it gives a better context to the reviews making it easier for classifier to classify them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this assignment, clothing Reviews- Preprocessing and Feature SelectionIn this assignment, you will use information about customers to predict whether the owner of a clothing review is a woman or man. The algorithms were then fed these representations to learn how review sentiment can be classified; the Bag-of-Words approach best dealt with it. Additional experiments to evaluate the efficacy of incorporating more features were also performed, and results obtained in this case demonstrate that the model accuracy increases by including both title and review text together with BoW features for classification.Text Classification:Further analysis of the usefulness offered by additional information was carried out here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
